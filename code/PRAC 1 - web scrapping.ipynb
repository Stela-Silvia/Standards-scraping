{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librerías que vamos a necesitar\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import time\n",
    "import unicodedata\n",
    "\n",
    "# Función para eliminar tildes        \n",
    "def elimina_tildes(cadena):\n",
    "    s = ''.join((c for c in unicodedata.normalize('NFD',cadena) if unicodedata.category(c) != 'Mn'))\n",
    "    return s\n",
    "\n",
    "# Creamos el documento .csv para guardar los campos de interés\n",
    "with open(\"Standards.csv\",\"w\", encoding=\"utf-8\") as csvfile:\n",
    "    spamwriter=csv.writer(csvfile, delimiter=';')  \n",
    "    # Cabecera\n",
    "    spamwriter.writerow(['CODIGO','DESCRIPCION', 'EMPRESA', 'CODIGO_NB', 'PAIS_NB', 'TELEFONO_NB', 'EMAIL_NB', 'WEB_NB'])\n",
    "    cnt=0\n",
    "    Datos=[]\n",
    "   \n",
    "    # Obtenemos los datos\n",
    "    #Calculamos el tiempo de respuesta para introducir retrasos en las peticiones consecutivas\n",
    "    for term in [\"web scraping\", \"web crawling\", \"scrape this site\"]:\n",
    "        t0 = time.time()\n",
    "        r = requests.get(\"https://ec.europa.eu/growth/tools-databases/nando/index.cfm?fuseaction=cp.hs&cpr=Y\", params=dict(query=term))\n",
    "       \n",
    "    ## Calculo final de la estimación del tiempo de respuesta en segundos\n",
    "    response_delay = time.time() - t0\n",
    "   \n",
    "    # Marcamos la url base para los enlaces siguientes extraidos de la web\n",
    "    url_base = 'https://ec.europa.eu/growth/tools-databases/nando/'\n",
    "   \n",
    "    # Listas para guardar los campos de interés\n",
    "    Codigo=[]\n",
    "    Descripcion=[]\n",
    "    Empresa=[]\n",
    "    nb=[]\n",
    "    Country=[]\n",
    "    Phone=[]\n",
    "    Email=[]\n",
    "    Web=[]\n",
    "   \n",
    "    # Cargamos la primera página, donde se encuentran el listado de normas armonizadas.\n",
    "    page = requests.get('https://ec.europa.eu/growth/tools-databases/nando/index.cfm?fuseaction=cp.hs&cpr=Y')\n",
    "    soup = BeautifulSoup(page.content)\n",
    "   \n",
    "    contador=-1\n",
    "   \n",
    "    # Recorremos la lista de normas:\n",
    "    for i in soup.find_all('a',{'class':'list'}):\n",
    "        # Cada norma introducimos un tiempo de espera para espaciar nuestras peticiones\n",
    "        # Espera de 10 veces el tiempo de respuesta\n",
    "        time.sleep(10 * response_delay)\n",
    "       \n",
    "        #####################\n",
    "        ### CAMPO CODIGO ###\n",
    "        #####################\n",
    "        codigo = i.string  # Valor a introducir en el campo: Codigo\n",
    "       \n",
    "        ###########################\n",
    "        ### CAMPO DESCRIPCION ###\n",
    "        ###########################\n",
    "   \n",
    "        cod_simple = re.findall('[A-Z]+ [0-9]*[-]*[0-9]*[:]*[0-9]*[/]*[+]*[A-Z]*[:]*[0-9]*', codigo)        \n",
    "        if cod_simple[0] == 'EN ISO':\n",
    "            cod_simple = re.findall('[A-Z]+ [A-Z]* [0-9]*[-]*[0-9]*[:]*[0-9]*[/]*[+]*[A-Z]*[:]*[0-9]*', codigo)\n",
    "        descripcion = soup.find_all(string=re.compile('\\t'+cod_simple[0]))\n",
    "       \n",
    "        try:\n",
    "            descripcion =(descripcion[0].strip())  # Valor a introducir en el campo: Descripcion\n",
    "        except IndexError:  \n",
    "            descripcion =\"---\"\n",
    "    #   print(descripcion)\n",
    "         \n",
    "        if contador==1:\n",
    "            break\n",
    "        else:\n",
    "            contador=contador+1\n",
    "   \n",
    "        # Cargamos la segunda página, de esta página no estraeremos datos con los que rellenar campos\n",
    "        # pero muestra un listado de los NB que pueden realizar la notificación de la norma que estamos\n",
    "        # tratando.\n",
    "        page2 = requests.get(url_base+i.get('href'))\n",
    "        soup2 = BeautifulSoup(page2.content)\n",
    "       \n",
    "        # Recorremos el listado de NB de la norma\n",
    "        for j in soup2.find_all('a',{'class':'list'}):\n",
    "            #Para cada empresa introducimos un tiempo de espera para espaciar nuestras peticiones\n",
    "            #Espera de 2 veces el tiempo de respuesta\n",
    "            time.sleep(2 * response_delay)\n",
    "           \n",
    "            #Para cada elemento de la segunda página, es decir, para cada NB cargamos una página\n",
    "            #en la que están sus datos.\n",
    "            page3 = requests.get(url_base+j.get('href'))\n",
    "            soup3 = BeautifulSoup(page3.content)\n",
    "   \n",
    "            #############################\n",
    "            ### CAMPO EMPRESA y WEB ###\n",
    "            #############################\n",
    "            for k in soup3.find_all('strong'):\n",
    "                empresa=(k.string) # Valor a introducir en el campo: Empresa\n",
    "                empresa=elimina_tildes(empresa)\n",
    "                Empresa.append(empresa)\n",
    "               \n",
    "                web=soup3.find('a',{'target':'_blank'})  # Valor a introducir en el campo: Web_NB\n",
    "                if web:\n",
    "                    # print(web.get('href'))\n",
    "                    Web.append(web.get('href'))\n",
    "                else:\n",
    "                    Web.append(\"---\")\n",
    "       \n",
    "            ##############################################\n",
    "            ### CAMPOS NB, PAIS, TELEFONO, EMAIL       ###\n",
    "            ##############################################\n",
    "            NB = soup3.find_all(string=re.compile(\"Notified Body number :\"))\n",
    "            aux = NB[0].replace('Notified Body number :', '')\n",
    "            NB = aux.strip() #Valor a introducir en el campo: Codigo_NB\n",
    "            nb.append(NB)\n",
    "   \n",
    "            country = soup3.find_all(string=re.compile(\"Country :\"))\n",
    "            aux = country[0].replace('Country :', '')\n",
    "            country = aux.strip() #Valor a introducir en el campo: Pais_NB\n",
    "            Country.append(country)\n",
    "   \n",
    "            phone = soup3.find_all(string=re.compile(\"Phone :\"))\n",
    "            aux = phone[0].replace('Phone :', '')\n",
    "            phone = aux.strip() #Valor a introducir en el campo: Telefono_NB\n",
    "            Phone.append(phone)\n",
    "   \n",
    "            email = soup3.find_all(string=re.compile(\"Email :\"))\n",
    "            aux = email[0].replace('Email :', '')\n",
    "            email = aux.strip() #Valor a introducir en el campo: Email_NB\n",
    "            Email.append(email)\n",
    "           \n",
    "            # Almacenamos el Código y la Descripción\n",
    "            Codigo.append(codigo)\n",
    "            Descripcion.append(descripcion)\n",
    "            \n",
    "            #############################\n",
    "            ### GUARDAMOS LOS DATOS ###\n",
    "            #############################  \n",
    "            # Montamos los datos en una fila y lo guardamos en el csv\n",
    "            Rows=[Codigo[cnt], Descripcion[cnt], Empresa[cnt], nb[cnt], Country[cnt], Phone[cnt], Email[cnt], Web[cnt]]\n",
    "            Datos.append(Rows)\n",
    "            # print(Datos[cnt])\n",
    "            spamwriter.writerow(Datos[cnt])\n",
    "            \n",
    "            #Imprimimos un aviso cada 25 registros para saber que el proceso continua. \n",
    "            if cnt%25 == 0:\n",
    "                print(\"Guardando fila... \" + str(cnt))\n",
    "            cnt=cnt+1\n",
    "\n",
    "csvfile.close()\n",
    "print(\"Proceso finalizado. \\nSe han guardado \"+str(cnt)+\" registros\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
